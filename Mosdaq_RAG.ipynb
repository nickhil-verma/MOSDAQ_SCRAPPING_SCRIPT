{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOqmlmOmXNe872lftg9TCZW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nickhil-verma/MOSDAQ_SCRAPPING_SCRIPT/blob/main/Mosdaq_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q pymongo[srv] sentence-transformers requests python-dotenv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhY9gJvaXtKN",
        "outputId": "7c91527f-2c7e-46fa-bdfd-a776c5770782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: pymongo 4.13.2 does not provide the extra 'srv'\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import requests\n",
        "import numpy as np\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# MongoDB + API\n",
        "MONGO_URI =  os.getenv(\"MONGO_URI\")\n",
        "API_URL =  os.getenv(\"API_URL\")\n",
        "\n",
        "# Connect Mongo\n",
        "client = MongoClient(MONGO_URI)\n",
        "db = client[\"isro_Hackathon\"]\n",
        "collection = db[\"vectors\"]\n",
        "collection.drop()  # Clear old vectors\n",
        "\n",
        "# Load embedding model\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
      ],
      "metadata": {
        "id": "v5pzKwlwXw_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_top_k_documents(query, k=3):\n",
        "    query_embedding = model.encode([query])\n",
        "\n",
        "    docs = list(collection.find({}, {\"_id\": 0}))\n",
        "    texts = [doc[\"text\"] for doc in docs]\n",
        "    embeddings = [np.array(doc[\"embedding\"]).reshape(1, -1) for doc in docs]\n",
        "    embeddings = np.vstack(embeddings)\n",
        "\n",
        "    similarities = cosine_similarity(query_embedding, embeddings)[0]\n",
        "    top_k_indices = np.argsort(similarities)[::-1][:k]\n",
        "\n",
        "    return [texts[i] for i in top_k_indices]\n"
      ],
      "metadata": {
        "id": "5Nzk0G_eX1fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_ollama(query, context, model_name=\"gemma\"):\n",
        "    prompt = f\"\"\"You are an expert assistant. Answer the following question using ONLY the provided context.\n",
        "If the answer is not in the context, say \"I don't know.\"\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            \"http://localhost:11434/api/generate\",\n",
        "            json={\n",
        "                \"model\": model_name,\n",
        "                \"prompt\": prompt,\n",
        "                \"stream\": False\n",
        "            }\n",
        "        )\n",
        "        return response.json().get(\"response\", \"‚ùå No response from model.\")\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error contacting Ollama: {e}\"\n",
        "\n"
      ],
      "metadata": {
        "id": "B04sdpGQX6tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_chatbot(question, model_name=\"gemma\"):\n",
        "    context_docs = get_top_k_documents(question)\n",
        "    combined_context = \"\\n\\n\".join(context_docs)\n",
        "\n",
        "    answer = ask_ollama(question, combined_context, model_name=model_name)\n",
        "\n",
        "    print(\"üîç Retrieved Context:\\n\", combined_context[:500], \"\\n\")\n",
        "    print(\"üß† LLM Answer:\\n\", answer)\n"
      ],
      "metadata": {
        "id": "WakkZmysa7I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chatbot(\"What kind of data does MOSDAC LIVE URJA use?\", model_name=\"gemma3\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S-m8IDNa9Nb",
        "outputId": "cdec707b-7cb5-415e-8ca4-5c4caa6a3967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Retrieved Context:\n",
            " MOSDAC Live ‚Äì URJA. MOSDAC-LIVE is a web-enabled data and information visualization and analysis system of MOSDAC, SAC/ISRO. The system provides access to satellite data products and information products derived from satellite and model forecast in near real time basis. The website is currently a beta site under development and contains data layers from various organizations. Data layers include imagery from INSAT3S (including TIR1, TIR2, MIR, SWIR, Visible, Water Vapour), SOUNDER, and various m \n",
            "\n",
            "üß† LLM Answer:\n",
            " ‚ùå Error contacting Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fbccdfc3e90>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_ollama(query, context, model_name=\"gemma\"):\n",
        "    prompt = f\"\"\"You are a helpful assistant. Answer the following question using ONLY the provided context.\n",
        "If the answer is not in the context, say \"I don't know\".\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    try:\n",
        "        res = requests.post(\n",
        "            \"http://localhost:11434/api/generate\",\n",
        "            json={\n",
        "                \"model\": model_name,\n",
        "                \"prompt\": prompt,\n",
        "                \"stream\": False\n",
        "            }\n",
        "        )\n",
        "        return res.json().get(\"response\", \"‚ùå No valid response.\")\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error contacting Ollama: {e}\"\n"
      ],
      "metadata": {
        "id": "Lye44WC_a_FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_chatbot(question, model_name=\"gemma\"):\n",
        "    top_contexts = get_top_k_documents(question)\n",
        "    combined_context = \"\\n\\n\".join(top_contexts)\n",
        "    answer = ask_ollama(question, combined_context, model_name=model_name)\n",
        "\n",
        "    print(\"üîç Retrieved Context:\\n\", combined_context[:500], \"\\n\")\n",
        "    print(\"üß† Answer:\\n\", answer)\n"
      ],
      "metadata": {
        "id": "bPpN2e6lbBje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chatbot(\"What kind of data does MOSDAC LIVE URJA use?\", model_name=\"gemma3\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "4r4NajcnbDkR",
        "outputId": "e202c91a-2fa0-46ea-8483-8e815db48b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found array with dim 3. check_pairwise_arrays expected <= 2.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-19-1637249803.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrag_chatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What kind of data does MOSDAC LIVE URJA use?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gemma3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-17-4229688009.py\u001b[0m in \u001b[0;36mrag_chatbot\u001b[0;34m(question, model_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrag_chatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gemma\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtop_contexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_top_k_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcombined_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_contexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mask_ollama\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-15-531382126.py\u001b[0m in \u001b[0;36mget_top_k_documents\u001b[0;34m(query, k)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_embedding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtop_k_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1741\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_all_finite, ensure_2d, copy)\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n\u001b[1;32m    199\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         X = check_array(\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1099\u001b[0m             )\n\u001b[1;32m   1100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1102\u001b[0m                 \u001b[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. check_pairwise_arrays expected <= 2."
          ]
        }
      ]
    }
  ]
}